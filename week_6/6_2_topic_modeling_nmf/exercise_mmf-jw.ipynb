{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Exercises: Topic Modeling with Non-Negative Matrix factorization (NMF) \n",
    "----\n",
    "\n",
    "Today we will apply the Non-Negative Matrix factorization (NMF) algorithm to discover latent topics in New York Times articles.\n",
    "\n",
    "![](http://1.bp.blogspot.com/_JNTikHKvtnY/S6tLPRWmxjI/AAAAAAAABcQ/-eszxl-WIQ0/s1600/New-York-Times.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Preprocessing\n",
    "----\n",
    "\n",
    "1) Read the articles.pkl file using the `df.read_pickle` function in Pandas and transform the data into a structure for sci-kit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../corpora/nyt_articles.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_type</th>\n",
       "      <th>web_url</th>\n",
       "      <th>lead_paragraph</th>\n",
       "      <th>abstract</th>\n",
       "      <th>snippet</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>word_count</th>\n",
       "      <th>source</th>\n",
       "      <th>section_name</th>\n",
       "      <th>subsection_name</th>\n",
       "      <th>_id</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>print_page</th>\n",
       "      <th>headline</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>article</td>\n",
       "      <td>http://www.nytimes.com/2013/10/03/sports/footb...</td>\n",
       "      <td>You would think that in a symmetric zero-sum s...</td>\n",
       "      <td>None</td>\n",
       "      <td>You would think that in a symmetric zero-sum s...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>347</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Pro Football</td>\n",
       "      <td>524d4e3a38f0d8198974001f</td>\n",
       "      <td>2013-10-03T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "      <td>Week 5 Probabilities: Why Offense Is More Impo...</td>\n",
       "      <td>the original goal building model football fore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>article</td>\n",
       "      <td>http://www.nytimes.com/2013/10/03/us/new-immig...</td>\n",
       "      <td>House Democrats on Wednesday unveiled an immig...</td>\n",
       "      <td>House Democrats unveil immigration bill that p...</td>\n",
       "      <td>House Democrats on Wednesday unveiled an immig...</td>\n",
       "      <td>National</td>\n",
       "      <td>83</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>None</td>\n",
       "      <td>524cf71338f0d8198973ff7b</td>\n",
       "      <td>2013-10-03T00:00:00Z</td>\n",
       "      <td>21</td>\n",
       "      <td>New Immigration Bill Put Forward</td>\n",
       "      <td>house unveiled immigration bill provides path ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  document_type                                            web_url  \\\n",
       "0       article  http://www.nytimes.com/2013/10/03/sports/footb...   \n",
       "1       article  http://www.nytimes.com/2013/10/03/us/new-immig...   \n",
       "\n",
       "                                      lead_paragraph  \\\n",
       "0  You would think that in a symmetric zero-sum s...   \n",
       "1  House Democrats on Wednesday unveiled an immig...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0                                               None   \n",
       "1  House Democrats unveil immigration bill that p...   \n",
       "\n",
       "                                             snippet news_desk word_count  \\\n",
       "0  You would think that in a symmetric zero-sum s...    Sports        347   \n",
       "1  House Democrats on Wednesday unveiled an immig...  National         83   \n",
       "\n",
       "               source section_name subsection_name                       _id  \\\n",
       "0  The New York Times       Sports    Pro Football  524d4e3a38f0d8198974001f   \n",
       "1  The New York Times         U.S.            None  524cf71338f0d8198973ff7b   \n",
       "\n",
       "               pub_date print_page  \\\n",
       "0  2013-10-03T00:00:00Z       None   \n",
       "1  2013-10-03T00:00:00Z         21   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Week 5 Probabilities: Why Offense Is More Impo...   \n",
       "1                   New Immigration Bill Put Forward   \n",
       "\n",
       "                                             content  \n",
       "0  the original goal building model football fore...  \n",
       "1  house unveiled immigration bill provides path ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look that data...\n",
    "# What are the columns?\n",
    "\n",
    "# columns are the features of the article\n",
    "\n",
    "# What are the rows?\n",
    "\n",
    "# individual articles\n",
    "\n",
    "df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the original goal building model football forecasting weigh importance facet game in particular want'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at a sample of the data - content of the news stories\n",
    "df.content[0][:100]\n",
    "\n",
    "# content of the news article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Use the [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) from scikit-learn to turn the content of the news stories into the document-term matrix $\\textbf{A}$ \n",
    "\n",
    "(I call it \"vectorized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here are some good defaults\n",
    "max_features=1000\n",
    "max_df=0.95,  \n",
    "min_df=2,\n",
    "max_features=1000,\n",
    "stop_words='english'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the size of the document-term matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1405, 1000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document-term matrix A\n",
    "vectorized = CountVectorizer(max_features=1000, max_df=0.95, min_df=2, stop_words='english')\n",
    "\n",
    "a = vectorized.fit_transform(df.content)\n",
    "a.shape\n",
    "\n",
    "# so n is 1405, and m is 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "NMF with scikit-learn \n",
    "------\n",
    "\n",
    "Hint: [Here is an example](http://scikit-learn.org/stable/auto_examples/applications/topics_extraction_with_nmf_lda.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "assert sklearn.__version__ == '0.18' # Make sure we are in the modern age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply NMF with SVD-based initialization to the document-term matrix $\\text{A}$ generate 4 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = NMF(init=\"nndsvd\",\n",
    "            n_components=4,\n",
    "            max_iter=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the factors $\\text{W}$ and $\\text{H}$ from the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = model.fit_transform(a)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is are sizes of W and H?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: (1405, 4)\n",
      "H: (4, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(\"W:\", W.shape)\n",
    "print(\"H:\", H.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the list of all terms whose indices correspond to the columns of the document-term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.feature_extraction.text.CountVectorizer"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = vectorized\n",
    "\n",
    "terms = [\"\"] * len(vectorizer.vocabulary_)\n",
    "for term in vectorizer.vocabulary_.keys():\n",
    "    terms[vectorizer.vocabulary_[term]] = term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yard', 'year', 'york', 'young', 'zone']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look that some of the terms\n",
    "terms[-5:]\n",
    "# terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the top 10 ranked terms for each topic, by sorting the values in the rows of the $\\text{H}$ factor \n",
    "\n",
    "<br>\n",
    "\n",
    "<details><summary>\n",
    "Click here for a hint…\n",
    "</summary>\n",
    "```\n",
    "for topic_index in None:\n",
    "    top_indices = np.argsort(None)[None][None]\n",
    "    term_ranking = [None[i] for i in None]\n",
    "    print(\"Topic {}: {}\".format(topic_index, \", \".join(term_ranking)))\n",
    "```\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "\n",
    "<details><summary>\n",
    "Click here for the answer…\n",
    "</summary>\n",
    "```\n",
    "for topic_index in range(H.shape[0]):\n",
    "    top_indices = np.argsort(H[topic_index,:])[::-1][0:10]\n",
    "    term_ranking = [terms[i] for i in top_indices]\n",
    "    print(\"Topic {}: {}\".format(topic_index, \", \".join(term_ranking)))\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: said, year, new, people, state, company, gun, work, like, percent\n",
      "Topic 1: game, season, said, team, year, player, time, play, yankee, league\n",
      "Topic 2: republican, government, house, health, law, care, party, shutdown, senate, president\n",
      "Topic 3: mr, said, iran, rouhani, united, nuclear, president, obama, state, netanyahu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for topic_index in range(H.shape[0]):  # H.shape[0] is k\n",
    "    top_indices = np.argsort(H[topic_index,:])[::-1][0:10]\n",
    "    term_ranking = [terms[i] for i in top_indices]\n",
    "    print(\"Topic {}: {}\".format(topic_index, \", \".join(term_ranking)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the words in the numbered topics. For each one, make-up a label that describes it.\n",
    "\n",
    "For example:  \n",
    "`Topic 3: people, mobile, said, phone, technology, music, digital, users, microsoft, software`  \n",
    "is about \"The Singularity\" 😉\n",
    "\n",
    "Are there any topics that don't make sense (i.e., the words don't go together)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "These are all a mix of the 10 section_names.\n",
    "\n",
    "Topic 0: said, year, new, people, state, company, gun, work, like, percent\n",
    "\n",
    "Business Day, business news, or front page headlines\n",
    "\n",
    "Topic 1: game, season, said, team, year, player, time, play, yankee, league\n",
    "\n",
    "sports\n",
    "\n",
    "Topic 2: republican, government, house, health, law, care, party, shutdown, senate, president\n",
    "\n",
    "domestic politics - U.S.\n",
    "\n",
    "Topic 3: mr, said, iran, rouhani, united, nuclear, president, obama, state, netanyahu\n",
    "\n",
    "foreign politics - World\n",
    "\n",
    "\n",
    "Topic 0 is not immediately obvious - if we try to catergorize it as business news, the word \"gun\" doesn't seem to go together.  Maybe it's Opinion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the number of topics to match the number of topics in NYT section labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arts',\n",
       " 'Books',\n",
       " 'Business Day',\n",
       " 'Magazine',\n",
       " 'Opinion',\n",
       " 'Real Estate',\n",
       " 'Sports',\n",
       " 'Travel',\n",
       " 'U.S.',\n",
       " 'World'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.section_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df.section_name))  # so there are 10 topics in NYT section labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: said, year, day, people, official, case, time, decision, court, added\n",
      "Topic 1: game, season, team, year, player, time, league, yankee, run, play\n",
      "Topic 2: republican, house, government, health, law, care, party, president, shutdown, obama\n",
      "Topic 3: mr, year, party, political, case, like, leader, state, court, night\n",
      "Topic 4: new, work, company, like, york, people, ms, job, worker, executive\n",
      "Topic 5: gun, child, death, year, law, state, time, shooting, old, killed\n",
      "Topic 6: iran, rouhani, nuclear, obama, iranian, netanyahu, president, israel, united, mr\n",
      "Topic 7: davis, state, story, texas, woman, democratic, city, new, republican, candidate\n",
      "Topic 8: percent, year, government, market, company, million, month, country, bank, economy\n",
      "Topic 9: united, government, syria, state, weapon, chemical, security, attack, official, nation\n"
     ]
    }
   ],
   "source": [
    "model = NMF(init=\"nndsvd\",\n",
    "            n_components=10,\n",
    "            max_iter=200)\n",
    "\n",
    "W = model.fit_transform(a)\n",
    "H = model.components_\n",
    "\n",
    "\n",
    "vectorizer = vectorized\n",
    "\n",
    "terms = [\"\"] * len(vectorizer.vocabulary_)\n",
    "for term in vectorizer.vocabulary_.keys():\n",
    "    terms[vectorizer.vocabulary_[term]] = term\n",
    "\n",
    "for topic_index in range(H.shape[0]):  # H.shape[0] is k\n",
    "    top_indices = np.argsort(H[topic_index,:])[::-1][0:10]\n",
    "    term_ranking = [terms[i] for i in top_indices]\n",
    "    print(\"Topic {}: {}\".format(topic_index, \", \".join(term_ranking)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "How do the NMF topics compare to the NYT section labels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "some are great like sports, the politics ones are harder to tell, except the domestic ones are obvious.  books is an enigma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Which would you use to filter your news?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I would use the NMF topics to choose sections that interested me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat with the same modeling with [`tf-idf`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: mr, said, court, case, judge, state, justice, lawyer, prison, official\n",
      "Topic 1: game, season, yard, team, said, league, player, coach, play, touchdown\n",
      "Topic 2: republican, house, health, care, government, senate, shutdown, obama, law, democrat\n",
      "Topic 3: iran, rouhani, nuclear, iranian, obama, israel, united, mr, netanyahu, president\n",
      "Topic 4: ms, music, art, new, work, like, dance, york, museum, song\n",
      "Topic 5: company, percent, said, market, year, million, bank, china, price, state\n",
      "Topic 6: yankee, rivera, pettitte, inning, game, season, baseball, run, pitch, stadium\n",
      "Topic 7: attack, said, official, syria, killed, people, government, police, security, mall\n",
      "Topic 8: party, merkel, government, germany, european, election, political, europe, german, ms\n",
      "Topic 9: cup, team, race, said, club, player, year, america, won, ve\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# document-term matrix A\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, max_df=0.95, min_df=2, stop_words='english')\n",
    "\n",
    "vectorized = tfidf_vectorizer\n",
    "\n",
    "a = vectorized.fit_transform(df.content)\n",
    "\n",
    "model = NMF(init=\"nndsvd\",\n",
    "            n_components=10,\n",
    "            max_iter=200)\n",
    "\n",
    "W = model.fit_transform(a)\n",
    "H = model.components_\n",
    "\n",
    "\n",
    "vectorizer = vectorized\n",
    "\n",
    "terms = [\"\"] * len(vectorizer.vocabulary_)\n",
    "for term in vectorizer.vocabulary_.keys():\n",
    "    terms[vectorizer.vocabulary_[term]] = term\n",
    "\n",
    "for topic_index in range(H.shape[0]):  # H.shape[0] is k\n",
    "    top_indices = np.argsort(H[topic_index,:])[::-1][0:10]\n",
    "    term_ranking = [terms[i] for i in top_indices]\n",
    "    print(\"Topic {}: {}\".format(topic_index, \", \".join(term_ranking)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does that change the topics?\n",
    "\n",
    "Are they \"tighter\"? Easier to describe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "yes!  they're way tigher, look at topic 6 (sports); tfidf is taking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Challenge Exercises\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rolling Your Own (RYO) NMF\n",
    "-----\n",
    "\n",
    "With the document matrix (our bags of words), we can begin implementing the NMF algorithm.  \n",
    "\n",
    "1. Create a NMF class to that is initialized with a document matrix (bag of words or tf-idf) __V__.  As arguments (in addition to the document matrix) it should also take parameters __k__ (# of latent topics) and the maximum # of iterations to perform. \n",
    "  \n",
    "  First we need to initialize our weights (__W__) and features (__H__) matrices.  \n",
    "\n",
    "2. Initialize the weights matrix (W) with (positive) random values to be a __n x k__ matrix, where __n__ is the number of documents and __k__ is the number of latent topics.\n",
    "\n",
    "2.  Initialize the feature matrix (H) to be __k x m__ where __m__ is the number of words in our vocabulary (i.e. length of bag).  Our original document matrix (__V__) is a __n x m__ matrix.  __NOTICE: shape(V) = shape(W * H)__\n",
    "\n",
    "3. Now that we have initialized our matrices and defined our cost, we can begin iterating. Update your weights and features matrices accordingly.  7. Repeat this update until convergence (i.e. change in __cost(V, W*H)__ close to 0). or until our max # of iterations.\n",
    "\n",
    "4. Assume we want to use a least-squares error metric when we update the matrices __W__ and __H__. This allows us to use the numpy.linalg.lstsq solver. \n",
    "Update __H__ by calling lstsq, holding __W__ fixed and minimizing the sum of squared errors predicting the document matrix. Since these values should all be at least 0, clip all the values in __H__ after the call to lstsq.\n",
    "\n",
    "5. Use the lstsq solver to update __W__ while holding __H__ fixed. The lstsq solver assumes it is optimizing the right matrix of the multiplication (e.g. x in the equation __ax=b__). So you will need to get creative so you can use it and have the dimensions line up correctly.  Brainstorm on paper or a whiteboard how to manipulate the matrices so lstsq can get the dimensionality correct and optimize __W__. __hint: it involves transposes.__ Clip __W__ appropriately after updating it with lstsq to ensure it is at least 0.  \n",
    "`from numpy.linalg import lstsq`\n",
    "\n",
    "6. Repeat steps 4 and 5 for a fixed number of iterations.\n",
    "\n",
    "7. Return the computed weights matrix and features matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Your NMF Function\n",
    "----\n",
    "\n",
    "1. Write a function that takes __W__, __H__ and the document matrix as arguments, and returns the mean-squared error (of __document matrix - WH__).\n",
    "\n",
    "2. Using argsort on each topic in __H__, find the index values of the words most associated with that topic.  Combine these index values with the word-names you stored in the __Preliminaries__ section to print out the most common words for each topic.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code you wrote for the __Using Your NMF Function__ on the SKlearn classifier.  How close is the output to what you found writing your own NMF classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Design an API__:\n",
    "1. Put your nmf function in an nmf class.\n",
    "2. Define a function that displays the headlines/titles of the top 10 documents for each topic.\n",
    "3. Define a function that takes as input a document and displays the top 3 topics it belongs to.\n",
    "4. Define a function that ensure consistent ordering between your nmf function and the sklearn nmf class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
