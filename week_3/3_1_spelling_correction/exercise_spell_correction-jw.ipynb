{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "Exercise: Spell Correction\n",
    "====\n",
    "\n",
    "<img src=\"https://s-media-cache-ak0.pinimg.com/236x/af/22/72/af2272d2f2f749c196407d724005f232.jpg\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "<img src=\"http://www.azquotes.com/picture-quotes/quote-simple-models-and-a-lot-of-data-trump-more-elaborate-models-based-on-less-data-peter-norvig-80-37-54.jpg\" style=\"width: 600px;\"/>\n",
    "\n",
    "Inspired by Peter Novig's [How to Do Things with Words in Python](http://nbviewer.jupyter.org/url/norvig.com/ipython/How%20to%20Do%20Things%20with%20Words.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "Spelling Correction Task\n",
    "----\n",
    "\n",
    "Given a word *w*, find the most likely correction *c* = `correct(`*w*`)`.\n",
    "\n",
    "__Approach:__ Try all candidate words *c* that are known words that are near *w*.  Choose the most likely one.\n",
    "\n",
    "How do we balance *near* and *likely*?\n",
    "\n",
    "For now, in a trivial way: always prefer nearer, but when there is a tie on nearness, use the word with the highest  count.  \n",
    "\n",
    "Measure nearness by *edit distance*: the minimum number of deletions, transpositions, insertions, or replacements of characters. By trial and error, we determine that going out to edit distance 2 will give us reasonable results.\n",
    "\n",
    "Then we can define `correct(`*w*`)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from string import string.ascii_lowercase as alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    \"Find the best spelling correction for this word.\"\n",
    "    # Prefer edit distance 0, then 1, then 2; otherwise default to word itself.\n",
    "    candidates = (known(edits0(word)) or \n",
    "                  known(edits1(word)) or \n",
    "                  known(edits2(word)) or \n",
    "                  [word])\n",
    "    return max(candidates, key=counts.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Norvig is doing a Pythonic thing with:  \n",
    "`(foo or \n",
    "bar or\n",
    "baz)`\n",
    "\n",
    "Learn more about it - https://docs.python.org/3/library/stdtypes.html#boolean-operations-and-or-not\n",
    "> This is a short-circuit operator, so it only evaluates the second argument if the first one is False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The functions `known` and `edits0` are easy; and `edits2` is easy if we assume we have `edits1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    \"Return the subset of words that are actually in the dictionary.\"\n",
    "    return {word for word in words \n",
    "                if word in counts}\n",
    "\n",
    "def edits0(word): \n",
    "    \"Return all strings that are zero edits away from word (i.e., just word itself).\"\n",
    "    return {word}\n",
    "\n",
    "def edits2(word):\n",
    "    \"Return all strings that are two edits away from this word.\"\n",
    "    return {e2 for e1 in edits1(word) \n",
    "                for e2 in edits1(e1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for `edits1(word)`: the set of candidate words that are one edit away. For example, given `\"wird\"`, this would include `\"weird\"` (inserting an `e`) and `\"word\"` (replacing a `i` with a `o`), and also `\"iwrd\"` (transposing `w` and `i`; then `known` can be used to filter this out of the set of final candidates). How could we get them?  One way is to *split* the original word in all possible places, each split forming a *pair* of words, `(a, b)`, before and after the place, and at each place, either delete, transpose, replace, or insert a letter:\n",
    "\n",
    "<table>\n",
    "  <tr><td> pairs: <td><tt> Ø+wird <td><tt> w+ird <td><tt> wi+rd <td><tt>wir+d<td><tt>wird+Ø<td><i>Notes:</i><tt> (<i>a</i>, <i>b</i>)</tt> pair</i>\n",
    "  <tr><td> deletions: <td><tt>Ø+ird<td><tt> w+rd<td><tt> wi+d<td><tt> wir+Ø<td><td><i>Delete first char of b</i>\n",
    "  <tr><td> transpositions: <td><tt>Ø+iwrd<td><tt> w+rid<td><tt> wi+dr</tt><td><td><td><i>Swap first two chars of b\n",
    "  <tr><td> replacements: <td><tt>Ø+?ird<td><tt> w+?rd<td><tt> wi+?d<td><tt> wir+?</tt><td><td><i>Replace char at start of b\n",
    "  <tr><td> insertions: <td><tt>Ø+?+wird<td><tt> w+?+ird<td><tt> wi+?+rd<td><tt> wir+?+d<td><tt> wird+?+Ø</tt><td><i>Insert char between a and b\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edits1(word):\n",
    "    \"Return all strings that are one edit away from this word.\"\n",
    "    pairs      = splits(word)\n",
    "    deletes    = [a+b[1:]           for (a, b) in pairs if b]\n",
    "    transposes = [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
    "    replaces   = [a+c+b[1:]         for (a, b) in pairs for c in alphabet if b]\n",
    "    inserts    = [a+c+b             for (a, b) in pairs for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def splits(word):\n",
    "    \"Return a list of all possible (first, rest) pairs that comprise word.\"\n",
    "    return [(word[:i], word[i:]) \n",
    "                for i in range(len(word)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# : Load the alphabet from Standard Library\n",
    "from string import ascii_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet = ascii_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert alphabet == 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 'wird'), ('w', 'ird'), ('wi', 'rd'), ('wir', 'd'), ('wird', '')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits('wird')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wird'}\n"
     ]
    }
   ],
   "source": [
    "print(edits0('wird'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wirdj', 'qwird', 'wtrd', 'werd', 'wir', 'wuird', 'ewird', 'wiid', 'wirdm', 'wcrd', 'wwrd', 'wrd', 'wirnd', 'wirzd', 'wirwd', 'wikrd', 'wwird', 'wirrd', 'wired', 'hird', 'wiord', 'wyrd', 'wirtd', 'bwird', 'ward', 'wirgd', 'ywird', 'wirdg', 'zwird', 'wigrd', 'wirde', 'wirdr', 'wimrd', 'wirfd', 'woird', 'weird', 'wlird', 'wjrd', 'widd', 'dwird', 'wibd', 'vwird', 'xird', 'bird', 'wire', 'wirdz', 'wiqd', 'wirsd', 'nird', 'wzrd', 'witrd', 'wivd', 'wrird', 'wibrd', 'tird', 'wirdo', 'wgird', 'wiryd', 'wirdb', 'zird', 'wiro', 'wiud', 'awird', 'wiyd', 'cwird', 'hwird', 'wicrd', 'iwird', 'wirvd', 'uwird', 'wpird', 'gird', 'wircd', 'wigd', 'wirdh', 'wirdt', 'fird', 'wirdy', 'iwrd', 'cird', 'wiod', 'wxrd', 'wirk', 'wid', 'wmird', 'fwird', 'wirkd', 'wixd', 'wirld', 'wiard', 'wirhd', 'wiad', 'aird', 'wsrd', 'lwird', 'wirdi', 'wurd', 'oird', 'wihrd', 'wirds', 'wqrd', 'wrid', 'wind', 'iird', 'wdird', 'wilrd', 'wisrd', 'wirdu', 'wihd', 'wiird', 'ird', 'lird', 'wira', 'wbird', 'wirdl', 'wirf', 'twird', 'kird', 'wirs', 'wirbd', 'widrd', 'wirod', 'wirxd', 'wfrd', 'wisd', 'jwird', 'wirdc', 'wiri', 'widr', 'wijd', 'kwird', 'pird', 'wsird', 'vird', 'wirm', 'wtird', 'wipd', 'wiry', 'wvrd', 'owird', 'whird', 'wirt', 'wxird', 'wiwrd', 'wirpd', 'wcird', 'wirz', 'wqird', 'wzird', 'wbrd', 'wizd', 'wierd', 'nwird', 'wirdn', 'wprd', 'wirdw', 'waird', 'wifrd', 'wird', 'wirad', 'wlrd', 'rird', 'wirq', 'wicd', 'rwird', 'wirb', 'wirc', 'wnird', 'wvird', 'wirda', 'wirdf', 'wikd', 'wijrd', 'wiprd', 'wirdq', 'wdrd', 'uird', 'witd', 'wirn', 'wirdx', 'wirj', 'wirjd', 'wirdp', 'wirw', 'wyird', 'winrd', 'wirv', 'wiqrd', 'wimd', 'wrrd', 'wirp', 'wirqd', 'wifd', 'wiwd', 'wirdd', 'xwird', 'whrd', 'wiru', 'wirud', 'jird', 'word', 'pwird', 'wirdv', 'wivrd', 'wixrd', 'wfird', 'wied', 'wirmd', 'wirx', 'wild', 'wirdk', 'yird', 'wirh', 'dird', 'wkird', 'wirl', 'wgrd', 'swird', 'wmrd', 'mird', 'wjird', 'sird', 'wirg', 'wiurd', 'wiyrd', 'mwird', 'wirid', 'wkrd', 'wirr', 'gwird', 'eird', 'qird', 'wnrd', 'wizrd'}\n"
     ]
    }
   ],
   "source": [
    "print(edits1('wird'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24,254\n"
     ]
    }
   ],
   "source": [
    "print(\"{:,}\".format(len(edits2('wird'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "Setup common functions and data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens(text):\n",
    "    \"List all the word tokens (consecutive letters) in a text. Normalize to lowercase.\"\n",
    "    return re.findall('[a-z]+', text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../../corpora/shakespeare_all.txt') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = tokens(text)\n",
    "counts = Counter(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Back to spell correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrase_uncorrected = 'Speling errurs in somethink. Whutever; unusuel misteakes everyware?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OG Token,  Corrected Token\n",
      "\n",
      "('speling', 'spelling')\n",
      "('errurs', 'errors')\n",
      "('in', 'in')\n",
      "('somethink', 'something')\n",
      "('whutever', 'whatever')\n",
      "('unusuel', 'unusual')\n",
      "('misteakes', 'mistakes')\n",
      "('everyware', 'everywhere')\n"
     ]
    }
   ],
   "source": [
    "phrase_corrected = map(correct, tokens(phrase_uncorrected))\n",
    "\n",
    "print(\"OG Token, \", \"Corrected Token\", end=\"\\n\\n\")\n",
    "print(*zip(tokens(phrase_uncorrected), \n",
    "           phrase_corrected), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Let's return a better formated result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_text(text):\n",
    "    \"Correct all the words within a text, returning the corrected text.\"\n",
    "    return re.sub('[a-zA-Z]+', correct_match, text)\n",
    "\n",
    "def correct_match(match):\n",
    "    \"Spell-correct word in match, and preserve proper upper/lower/title case.\"\n",
    "    word = match.group()\n",
    "    return case_of(word)(correct(word.lower()))\n",
    "\n",
    "def case_of(text):\n",
    "    \"Return the case-function appropriate for text: upper, lower, title, or just str.\"\n",
    "    return (str.upper if text.isupper() else\n",
    "            str.lower if text.islower() else\n",
    "            str.title if text.istitle() else\n",
    "            str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our best guess for misspelled words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speling errurs in somethink. Whutever; unusuel misteakes everyware?\n",
      "Spelling errors in something. Whatever; unusual mistakes everywhere?\n"
     ]
    }
   ],
   "source": [
    "print(phrase_uncorrected)\n",
    "print(correct_text(phrase_uncorrected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audiance sayzs: spealling is difffucult...\n",
      "Audience says: spelling is difficult...\n"
     ]
    }
   ],
   "source": [
    "phrase_uncorrected_2 = 'Audiance sayzs: spealling is difffucult...'\n",
    "print(phrase_uncorrected_2)\n",
    "# print(correct_text(correct_text(phrase_uncorrected_2)))\n",
    "print(correct_text(phrase_uncorrected_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phase_harder = \"the elegant lady entered the room\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the element lady entered the room\n"
     ]
    }
   ],
   "source": [
    "print(correct_text(phase_harder)) # Yikes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn.meme.am/cache/instances/folder5/500x/66510005.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Improve spellchecker with MOAR DATA. Load and use unigram counts\n",
    "\n",
    "# with open('/Users/justin/OneDrive/gU/DSCI6004-student/corpora/unigram_word_counts.txt') as f:\n",
    "#     text = f.read()\n",
    "\n",
    "with open('../../corpora/unigram_word_counts.txt') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OG Token,  Corrected Token\n",
      "\n",
      "('speling', 'speling')\n",
      "('errurs', 'errors')\n",
      "('in', 'in')\n",
      "('somethink', 'something')\n",
      "('whutever', 'whatever')\n",
      "('unusuel', 'unusual')\n",
      "('misteakes', 'mistakes')\n",
      "('everyware', 'evercare')\n"
     ]
    }
   ],
   "source": [
    "words = tokens(text)\n",
    "counts = Counter(words)\n",
    "\n",
    "phrase_corrected = map(correct, tokens(phrase_uncorrected))\n",
    "\n",
    "print(\"OG Token, \", \"Corrected Token\", end=\"\\n\\n\")\n",
    "print(*zip(tokens(phrase_uncorrected), \n",
    "           phrase_corrected), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the elegant lady entered the room\n"
     ]
    }
   ],
   "source": [
    "phase_harder = \"the elegant lady entered the room\"\n",
    "print(correct_text(phase_harder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert phase_harder == correct_text(phase_harder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you wrote lament, fllight, but you meant elegant\n"
     ]
    }
   ],
   "source": [
    "phase_haderest = \"you wrote elagent, elligit, but you meant elegant\"\n",
    "print(correct_text(phase_haderest)) # Better but not great, yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#: Load common spelling errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# /Users/justin/OneDrive/gU/DSCI6004-student/corpora/spell_errors.txt\n",
    "\n",
    "with open('../../corpora/spell_errors.txt') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "# words = tokens(text)\n",
    "# counts = Counter(words)\n",
    "\n",
    "# phrase_corrected = map(correct, tokens(phrase_uncorrected))\n",
    "\n",
    "# print(\"OG Token, \", \"Corrected Token\", end=\"\\n\\n\")\n",
    "# print(*zip(tokens(phrase_uncorrected), \n",
    "#            phrase_corrected), sep=\"\\n\")\n",
    "\n",
    "text = text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# phase_haderest = \"you wrote elagent, elligit, but you meant elegant\"\n",
    "# print(correct_text(correct_text(phase_haderest))) # Better but not great, yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 listen: lisen, lesson, lisn, leasten, listern*2\n",
      "1871 at_least: atleast\n",
      "5093 least: lest\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(text)):\n",
    "    if \"least\" in text[i]:\n",
    "        print(i, text[i])\n",
    "#     text[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['at_least', ' atleast']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spell_errors['raining']\n",
    "\n",
    "# text[0]\n",
    "# re.findall('(\\w+):', text[0])[0]  # this returns the key\n",
    "text[1871].split(\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' atleast']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re.findall('[a-z]+', text[0])[1:]  # this returns the value as a list\n",
    "text[1871].split(\":\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spell_errors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(text)-1):\n",
    "    key = text[i].split(\":\")[0]\n",
    "#     print(text[1871])\n",
    "    key = key.replace(\"_\", \" \")\n",
    "    spell_errors[key] = re.findall('[a-z]+', text[i])[1:]\n",
    "    \n",
    "# spell_errors['at least']\n",
    "\n",
    "# for x in spell_errors.keys():\n",
    "# text[i].split(\":\")[0]\n",
    "# text[1871].split(\":\")[0]\n",
    "# spell_errors['at least'], spell_errors['at least']\n",
    "# spell_errors['at least']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-028a1cfc19b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mspell_errors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raining'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'rainning'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'raning'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mspell_errors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'at least'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'atleast'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert spell_errors['raining'] == ['rainning', 'raning']\n",
    "assert spell_errors['at least'] == ['atleast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Rewrite \"correct\" function to use common errors if applicable otherwise default to old methdod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def correct(word):\n",
    "#     candidate = (known(edits0(word).....\n",
    "    \n",
    "#     correct_common_mistake = [key for key, values in spell_errors.itemms()\n",
    "#                              if word in values]\n",
    "    \n",
    "#     if correct_common_mistake:\n",
    "#         return correct_common_mistake[0]\n",
    "#     else:\n",
    "#         return max(candidates, key=counts.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert correct_text(\"elagent\") == \"elegant\"\n",
    "assert correct_text(\"elligit\") == \"elegant\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
